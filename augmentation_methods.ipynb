{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4b6cf5",
   "metadata": {},
   "source": [
    "# Mathematical Image Analysis Final Project: Dataset Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73712f9",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a98788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe483914",
   "metadata": {},
   "source": [
    "## import sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be76ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image using OpenCV (note: this loads in BGR format)\n",
    "img = cv2.imread('motorcycle.jpg')\n",
    "# Convert BGR to RGB for display\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Motorcycle Image')\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "# get image as numpy array\n",
    "img_array = np.array(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e5a7f",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing exposure/brightness {brightening (1.5)}\n",
    "def change_brightness(image, factor):\n",
    "    \"\"\"\n",
    "    Change the brightness of an image by multiplying pixel values by a factor.\n",
    "    :param image: Input image (numpy array)\n",
    "    :param factor: Brightness factor (1.0 = no change, <1.0 = darker, >1.0 = brighter)\n",
    "    :return: Brightened image (numpy array)\n",
    "    \"\"\"\n",
    "    # Create brightened versions of the image with different intensity factors\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Original image\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('on')\n",
    "\n",
    "    # Increase brightness by multiplying pixel values\n",
    "    # Clip to ensure values stay within valid range (0-255)\n",
    "    brightened = np.clip(image.astype(float) * factor, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Display the brightened image\n",
    "    plt.imshow(brightened)\n",
    "    plt.title(f'Brightness factor: {factor}')\n",
    "    plt.axis('on')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return brightened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_contrast(image, factor):\n",
    "    \"\"\"\n",
    "    Change the contrast of an image by adjusting pixel values around the mean.\n",
    "    \n",
    "    :param image: Input image (numpy array)\n",
    "    :param factor: Contrast factor (1.0 = no change, <1.0 = lower contrast, >1.0 = higher contrast)\n",
    "    :return: Contrast adjusted image (numpy array)\n",
    "    \"\"\"\n",
    "    # Calculate the mean pixel value as the reference point\n",
    "    mean = np.mean(image, axis=(0, 1))\n",
    "    \n",
    "    # Adjust the contrast by moving pixel values away from or toward the mean\n",
    "    # Formula: new_pixel = mean + factor * (old_pixel - mean)\n",
    "    adjusted = mean + factor * (image.astype(float) - mean)\n",
    "    \n",
    "    # Clip to ensure values stay within valid range (0-255)\n",
    "    adjusted = np.clip(adjusted, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Display the original and contrast-adjusted images\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('on')\n",
    "    \n",
    "    # Contrast adjusted image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(adjusted)\n",
    "    plt.title(f'Contrast factor: {factor}')\n",
    "    plt.axis('on')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9426f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_saturation(image, factor):\n",
    "    \"\"\"\n",
    "    Change the saturation of an image by converting to HSV, adjusting saturation, and converting back to RGB.\n",
    "    \n",
    "    :param image: Input image (numpy array)\n",
    "    :param factor: Saturation factor (1.0 = no change, <1.0 = less saturated, >1.0 = more saturated)\n",
    "    :return: Saturation adjusted image (numpy array)\n",
    "    \"\"\"\n",
    "    # Convert the image from RGB to HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Adjust the saturation channel\n",
    "    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * factor, 0, 255)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    adjusted = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    # Display the original and saturation-adjusted images\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('on')\n",
    "    \n",
    "    # Saturation adjusted image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(adjusted)\n",
    "    plt.title(f'Saturation factor: {factor}')\n",
    "    plt.axis('on')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b187921b",
   "metadata": {},
   "source": [
    "## Point operations (I.4):  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eadbcf0",
   "metadata": {},
   "source": [
    "### low brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0930eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_brightness = change_brightness(img_rgb, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa87f7",
   "metadata": {},
   "source": [
    "### high brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef4a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_brightness = change_brightness(img_rgb, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d677462",
   "metadata": {},
   "source": [
    "### high contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast enhancement (I.6)\n",
    "high_contrast = change_contrast(img_rgb, 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3de80c",
   "metadata": {},
   "source": [
    "### low contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_contrast = change_contrast(img_rgb, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7af9b3",
   "metadata": {},
   "source": [
    "### high saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d30ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhancing saturation\n",
    "high_saturation = change_saturation(img_rgb, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837d2da",
   "metadata": {},
   "source": [
    "### black & white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to black and white\n",
    "black_white = change_saturation(img_rgb, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducing random salt and pepper noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ffcdc",
   "metadata": {},
   "source": [
    "# Filtering using convolution (I.7, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution2d(image, kernel, stride=1):\n",
    "    \"\"\"\n",
    "    Helper function to perform a 2D convolution on an image with a given kernel.\n",
    "    Parameters:\n",
    "    - image: 2D numpy array representing the input image\n",
    "    - kernel: 2D numpy array representing the convolution kernel\n",
    "    - stride: integer, the step size for the convolution (1)\n",
    "    Returns:\n",
    "    - output: 2D numpy array representing the convolved image\n",
    "    \"\"\"\n",
    "    \n",
    "    # get dimensions\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    # pads to keep output the same size as input\n",
    "    pad_h = (kernel_height - 1) // 2\n",
    "    pad_w = (kernel_width - 1) // 2\n",
    "\n",
    "    # output array\n",
    "    output_height = (image_height - kernel_height + 2 * pad_h) // stride + 1\n",
    "    output_width = (image_width - kernel_width + 2 * pad_w) // stride + 1\n",
    "\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    padded_image = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='reflect')\n",
    "\n",
    "    # convolve image and filter\n",
    "    for y in range(output_height):\n",
    "        for x in range(output_width):\n",
    "            region = padded_image[y * stride:y * stride + kernel_height,\n",
    "                                  x * stride:x * stride + kernel_width]\n",
    "            output[y, x] = np.sum(region * kernel)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fa0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Blur (example of weighted averaging filter (I.12))\n",
    "def gaussian_blur(image, kernel_size=9, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Apply Gaussian blur to an image using a Gaussian kernel (handles RGB images).\n",
    "    Parameters:\n",
    "    - image: 2D numpy array representing the input image\n",
    "    - kernel_size: size of the Gaussian kernel (must be odd)\n",
    "    - sigma: standard deviation of the Gaussian distribution\n",
    "    Returns:\n",
    "    - blurred_image: 2D numpy array representing the blurred image\n",
    "    \"\"\"\n",
    "    \n",
    "    # set up the kernel\n",
    "    gaussian_blur_kernel = np.zeros((kernel_size, kernel_size), dtype=np.float32)\n",
    "    center = kernel_size // 2\n",
    "    for x in range(kernel_size):\n",
    "        for y in range(kernel_size):\n",
    "            gaussian_blur_kernel[x, y] = (1 / (2 * np.pi * sigma ** 2)) * \\\n",
    "                np.exp(-((x - center) ** 2 + (y - center) ** 2) / (2 * sigma ** 2))\n",
    "    gaussian_blur_kernel /= np.sum(gaussian_blur_kernel)\n",
    "\n",
    "    # handle grayscale and RGB images\n",
    "    if image.ndim == 2:\n",
    "        return convolution2d(image, gaussian_blur_kernel)\n",
    "    elif image.ndim == 3:\n",
    "        blurred_channels = [\n",
    "            convolution2d(image[:, :, c], gaussian_blur_kernel)\n",
    "            for c in range(image.shape[2])\n",
    "        ]\n",
    "        return np.stack(blurred_channels, axis=-1)\n",
    "    \n",
    "\n",
    "# test the Gaussian blur function\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Original\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(cv2.GaussianBlur(img_rgb, (9, 9), sigmaX=1.0))\n",
    "plt.title(\"OpenCV Blur\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(gaussian_blur(img_rgb, kernel_size=9, sigma=1.0).astype(np.uint8))\n",
    "plt.title(\"Manual Blur\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpen the image (I.57)\n",
    "def sharpen_image(image):\n",
    "    \"\"\"\n",
    "    Sharpen the image using a Laplacian kernel.\n",
    "    Parameters:\n",
    "    - image: 2D numpy array representing the input image\n",
    "    Returns:\n",
    "    - sharpened_image: 2D numpy array representing the sharpened image\n",
    "    \"\"\"\n",
    "    # define kernel\n",
    "    laplacian_kernel = np.array([[0, 1, 0],\n",
    "                                 [1, -4, 1],\n",
    "                                 [0, 1, 0]], dtype=np.float32)\n",
    "\n",
    "    if image.ndim == 3:\n",
    "        sharpened = np.stack([\n",
    "            image[:, :, c] - convolution2d(image[:, :, c], laplacian_kernel)\n",
    "            for c in range(image.shape[2])\n",
    "        ], axis=-1)\n",
    "    else:\n",
    "        sharpened = image - convolution2d(image, laplacian_kernel)\n",
    "\n",
    "    return np.clip(sharpened, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "# get openCV Laplacian sharpened image in rgb\n",
    "def opencv_sharpen(image):\n",
    "    \"\"\"\n",
    "    Sharpen the image using OpenCV's Laplacian operator. Handles RGB images.\n",
    "    Parameters:\n",
    "    - image: 3D numpy array (RGB image)\n",
    "    Returns:\n",
    "    - sharpened_image: 3D numpy array (sharpened RGB image)\n",
    "    \"\"\"\n",
    "    # convert to float for precisions\n",
    "    image = image.astype(np.float32)  \n",
    "    # apply Laplacian on each channel (R, G, B)\n",
    "    sharpened_image = np.zeros_like(image)\n",
    "    for c in range(image.shape[2]): \n",
    "        laplacian = cv2.Laplacian(image[:, :, c], cv2.CV_32F, ksize=3)\n",
    "        sharpened_image[:, :, c] = image[:, :, c] - laplacian\n",
    "\n",
    "    # return the sharpened image as integer data \n",
    "    return np.clip(sharpened_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "# test the sharpen function\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(sharpen_image(img_rgb))\n",
    "plt.title(\"Manual Sharpened\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(opencv_sharpen(img_rgb))\n",
    "plt.title(\"OpenCV Laplacian Sharpened\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9956d5ff",
   "metadata": {},
   "source": [
    "# Other (from linear algebra review):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6405ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed/Random rotation\n",
    "def rotate_image(image, angle):\n",
    "    \"\"\"\n",
    "    Rotate the image by a given angle.\n",
    "    Parameters:\n",
    "    - image: 2D numpy array representing the input image\n",
    "    - angle: angle in degrees to rotate the image\n",
    "    Returns:\n",
    "    - rotated_image: 2D numpy array representing the rotated image\n",
    "    \"\"\"\n",
    "    if angle == 0:\n",
    "        return image\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "    rotated_image = np.zeros_like(image)\n",
    "\n",
    "    # Convert angle to radians\n",
    "    theta = math.radians(angle)\n",
    "    cos_theta = math.cos(theta)\n",
    "    sin_theta = math.sin(theta)\n",
    "\n",
    "    # Rotation center\n",
    "    cx, cy = width // 2, height // 2\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            # shift to origin\n",
    "            xt = x - cx\n",
    "            yt = y - cy\n",
    "\n",
    "            # apply rotation\n",
    "            xr = cos_theta * xt - sin_theta * yt\n",
    "            yr = sin_theta * xt + cos_theta * yt\n",
    "\n",
    "            # shift back\n",
    "            src_x = int(round(xr + cx))\n",
    "            src_y = int(round(yr + cy))\n",
    "\n",
    "            # if within bounds, assign pixel\n",
    "            if 0 <= src_x < width and 0 <= src_y < height:\n",
    "                rotated_image[y, x] = image[src_y, src_x]\n",
    "\n",
    "    return rotated_image\n",
    "\n",
    "# test the rotation function\n",
    "img = cv2.imread('motorcycle.jpg')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Prepare figure\n",
    "angles = [0, 30, 45, 60, 90, 180, 225, 270]\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, angle in enumerate(angles):\n",
    "    rotated = rotate_image(img_rgb, angle)\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(rotated)\n",
    "    plt.title(f'{angle} Rotation')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d3149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shearing; typically padded with 0s (I.9), change in basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa274e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping image (reflection) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
